{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/playlist?list=PLzMcBGfZo4-lUA8uGjeXhBUUzPYc6vZRn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #import opencv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.imread(): Reading Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image = cv2.imread(r\"C:\\Users\\lenovo 61IN\\Desktop\\opencv\\samples\\data\\baboon.jpg\", -1) #read image\n",
    "\n",
    "# print(image) # displays the array of pixels of the image\n",
    "\n",
    "cv2.imshow(\"Image\", image) #display image\n",
    "cv2.waitKey(0) #wait for a key press\n",
    "cv2.destroyAllWindows() #close all opencv windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "image1 = cv2.imread(r\"C:\\Users\\lenovo 61IN\\Desktop\\opencv\\samples\\data\\orange.jpg\", -1)\n",
    "\n",
    "print(image1.shape) #output will be height, width, channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cv2.imwrite(): To write a image to a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"new_image.png\", image) #write a image to a new file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.cvtColor(): Converts an image from one color space to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(r\"C:\\Users\\lenovo 61IN\\Desktop\\opencv\\samples\\data\\baboon.jpg\")\n",
    "\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Convert the image from BGR to Grayscale\n",
    "\n",
    "cv2.imshow(\"Gray Image\", gray_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.resize(): For resizing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.resize(image, (100,100))\n",
    "\n",
    "cv2.imshow(\"Resized Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using fx and fy to give the ratio of increase and decrease in the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.resize(image, (0,0), fx = 2, fy = 2)\n",
    "\n",
    "cv2.imshow(\"Resized Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2.rotate(): For rotating images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "cv2.imshow(\"Resized Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(r\"C:\\Users\\lenovo 61IN\\Desktop\\opencv\\samples\\data\\lena.jpg\", -1)\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "\n",
    "# 0 = flip the image vertically\n",
    "# 1 = flip the image horizontally\n",
    "# -1 = flip the image both horizontally and vertically\n",
    "flip = cv2.flip(image, 1) \n",
    "\n",
    "cv2.imshow(\"flipped image\", flip)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHanging the pixel value of input image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "image2 = cv2.imread(r\"C:\\Users\\lenovo 61IN\\Desktop\\opencv\\samples\\data\\lena.jpg\", -1)\n",
    "\n",
    "#changing the pixel values of the first 100 rows and of all the columns\n",
    "for i in range(100): # taking first 100 rows\n",
    "    for j in range(image2.shape[1]): # here shape[1] denotes the column index returned when using image.shape() --> O/P: (rows, columns, channels)\n",
    "        image2[i][j] = [random.randint(0,255), random.randint(0,255), random.randint(0,255)] # setting the specific image index to random pixel values using random.randint()\n",
    "\n",
    "cv2.imshow(\"Image\", image2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying a part of the image into another position on the image using numpy slicing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "image2 = cv2.imread(r\"C:\\Users\\lenovo 61IN\\Desktop\\opencv\\samples\\data\\lena.jpg\", -1)\n",
    "\n",
    "print(image2.shape)\n",
    "\n",
    "#We are using numpy slicing to copy a part of the image\n",
    "# #copy\n",
    "tag = image2[100:200, 300:400] # in the image2, slice the rows from 100 to 200 and in those sliced rows copy 300 to 400 column pixels\n",
    "\n",
    "#paste\n",
    "image2[400:500, 200:300] = tag \n",
    "\n",
    "\n",
    "cv2.imshow(\"Image\", image2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Videos/ Frames from Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VideoCapture object to capture video from webcam\n",
    "cap = cv2.VideoCapture(0)  # Use '0' for default webcam device\n",
    "\n",
    "# Read and display frames from the webcam\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # for converting the color video stream to gray color\n",
    "    # Check if the webcam was successfully opened\n",
    "    if not ret:\n",
    "        print(\"Error opening camera\")\n",
    "        break\n",
    "    cv2.imshow('Webcam', frame)\n",
    "\n",
    "    #cv2.imshow('Webcam', gray) # for displaying gray frame from video\n",
    "\n",
    "    # Wait for a key press and check if the 'q' key was pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0) #use camera resource\n",
    "\n",
    "while True:\n",
    "    # here 'frame' is the image itself which is a numpy array. & 'ret' shows if the capture worked properly or not\n",
    "    ret, frame = cap.read()  \n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release() #release the camera resource\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gettign the width and Height of capture using cap.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) #use camera resource\n",
    "\n",
    "while True:\n",
    "    # here 'frame' is the image itself which is a numpy array. & 'ret' shows if the capture worked properly or not\n",
    "    ret, frame = cap.read()  \n",
    "    width = int(cap.get(3)) #width\n",
    "    height = int(cap.get(4)) #height\n",
    "\n",
    "    image = np.zeros(frame.shape, np.uint8 ) # to paste image from 'frame' into this window\n",
    "    smaller_frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "    \n",
    "    cv2.imshow('frame', image)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release() #release the camera resource\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mirroring Videos multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0) #use camera resource\n",
    "\n",
    "while True:\n",
    "    # here 'frame' is the image itself which is a numpy array. & 'ret' shows if the capture worked properly or not\n",
    "    ret, frame = cap.read()  \n",
    "\n",
    "    # height = int(cap.get(3))\n",
    "    # width = int(cap.get(4))\n",
    "\n",
    "    # Get the dimensions of the frame\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Resize the frame to half its size\n",
    "    smaller_frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "    \n",
    "    # Create a black image with the same dimensions as the frame\n",
    "    image = np.zeros((height,width, 3) ,np.uint8 ) # to paste image from 'frame' into this window\n",
    "\n",
    "    image[:height//2, :width//2] = smaller_frame # taking the smaller_frame and pasting it to the top left corner of 'image'\n",
    "    image[height//2:, :width//2] = smaller_frame # pasting it to the bottom left corner\n",
    "    image[:height//2, width//2:] = smaller_frame #  top right corner\n",
    "    image[height//2:, width//2:] = smaller_frame  # bottom right\n",
    "\n",
    "    cv2.imshow('frame', image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release() #release the camera resource\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotating frame in each window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (320,240,3) into shape (240,320,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create a black image with the same dimensions as the frame\u001b[39;00m\n\u001b[0;32m     17\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((height,width, \u001b[38;5;241m3\u001b[39m) ,np\u001b[38;5;241m.\u001b[39muint8 ) \u001b[38;5;66;03m# to paste image from 'frame' into this window\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mimage\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mrotate(smaller_frame, cv2\u001b[38;5;241m.\u001b[39mROTATE_90_COUNTERCLOCKWISE) \u001b[38;5;66;03m# taking the smaller_frame and pasting it to the top left corner of 'image'\u001b[39;00m\n\u001b[0;32m     20\u001b[0m image[height\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m:, :width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m smaller_frame \u001b[38;5;66;03m# pasting it to the bottom left corner\u001b[39;00m\n\u001b[0;32m     21\u001b[0m image[:height\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m=\u001b[39m smaller_frame \u001b[38;5;66;03m#  top right corner\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (320,240,3) into shape (240,320,3)"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0) #use camera resource\n",
    "\n",
    "while True:\n",
    "    # here 'frame' is the image itself which is a numpy array. & 'ret' shows if the capture worked properly or not\n",
    "    ret, frame = cap.read()  \n",
    "\n",
    "    # height = int(cap.get(3))\n",
    "    # width = int(cap.get(4))\n",
    "\n",
    "    # Get the dimensions of the frame\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Resize the frame to half its size\n",
    "    smaller_frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "    \n",
    "    # Create a black image with the same dimensions as the frame\n",
    "    image = np.zeros((height,width, 3) ,np.uint8 ) # to paste image from 'frame' into this window\n",
    "\n",
    "    image[:height//2, :width//2] = cv2.rotate(smaller_frame, cv2.ROTATE_90_COUNTERCLOCKWISE) # taking the smaller_frame and pasting it to the top left corner of 'image'\n",
    "    image[height//2:, :width//2] = smaller_frame # pasting it to the bottom left corner\n",
    "    image[:height//2, width//2:] = smaller_frame #  top right corner\n",
    "    image[height//2:, width//2:] = smaller_frame  # bottom right\n",
    "\n",
    "    cv2.imshow('frame', image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release() #release the camera resource\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THE ABOVE ERROR WHEN TRYING TO ROTATE THE FRAME 90 DEGREE USING cv2.rotate() IS BECAUSE WHEN WE ROTATE THE FRAME THE HEIGHT AND WIDTH OF THE INPUT FRAME/IMAGE IS SWAPPED AND WONT BE ABLE TO ACCOMODATE IN THE WINDOWS WE HAVE PARTITIONED. INSTEAD WE CAN USE ROTATE_180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) #use camera resource\n",
    "\n",
    "while True:\n",
    "    # here 'frame' is the image itself which is a numpy array. & 'ret' shows if the capture worked properly or not\n",
    "    ret, frame = cap.read()  \n",
    "\n",
    "    # height = int(cap.get(3))\n",
    "    # width = int(cap.get(4))\n",
    "\n",
    "    # Get the dimensions of the frame\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Resize the frame to half its size\n",
    "    smaller_frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "    \n",
    "    # Create a black image with the same dimensions as the frame\n",
    "    image = np.zeros((height,width, 3) ,np.uint8 ) # to paste image from 'frame' into this window\n",
    "\n",
    "    image[:height//2, :width//2] = cv2.rotate(smaller_frame, cv2.ROTATE_180) # rotating the image top left corner of 'image'\n",
    "    image[height//2:, :width//2] = smaller_frame # pasting it to the bottom left corner\n",
    "    image[:height//2, width//2:] = cv2.rotate(smaller_frame, cv2.ROTATE_180) #  top right corner\n",
    "    image[height//2:, width//2:] = smaller_frame  # bottom right\n",
    "\n",
    "    cv2.imshow('frame', image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release() #release the camera resource\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  DRAWING SHAPES: LINE, RECTANGLE. CIRCLE & TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    width = int(cap.get(3))\n",
    "    height = int(cap.get(4))\n",
    "\n",
    "    # here cv2.line is used to draw line on the image. the below function specifies the starting and \n",
    "    #ending coordinates of the line which is (0,0) -> top-left corner to (width, height) -> bottom-right corner\n",
    "    img = cv2.line(frame, (0,0), (width,height), (0,255,0), 10)\n",
    "\n",
    "    # the below line of code is to draw a line on top of the line drawn from the above line of code as to cross over the existing line. \n",
    "    #hence we pass the previous variable which is 'line' as a parameter to the below code\n",
    "    img = cv2.line(img, (0,height), (width,0), (0,0, 255), 10)\n",
    "\n",
    "    # cv2.rectangle() is used to draw a rectangle inside an image. the paramters are (image, starting-point, ending-point, color, thickness)\n",
    "    #NOTE: If thickness is set to -1 then the rectangle will be filled with the specified color. any other value is considered as a thickness of the lines of rectangle. \n",
    "    img = cv2.rectangle(img, (100,100), (200,200), (120,64,200), -1)\n",
    "\n",
    "    # cv2.circle() is used to draw a circle on the image. the parameters are (source image, (co-ordinates of the cnter of the circle), (radius), (color), thickness)\n",
    "    # th eboave thickness value property of -1 applies here as well.\n",
    "    img - cv2.circle(img, (200,100), 60, (255,0,0), 3)\n",
    "\n",
    "    #it's a standard practice to set the font prior to using cv2.putText() method. so the below line sets the font for the text we want to put on the image.\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "    #cv2.putText() is used to put text on the image. paramters are: (source-image, text, starting co-ordinates, font, font-scale, color, thickness, font-style )\n",
    "    img = cv2.putText(img, 'Lets learn and master opencv', (10, height-10), font, 1, (120,250,100), 5, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Frame', img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  cv2.threshold():\n",
    "\n",
    "Purpose: This function is used to apply a fixed-level thresholding to each pixel in an image, which converts grayscale images into binary images.\n",
    "\n",
    "Parameters:\n",
    "src: The input image (single-channel, grayscale).\n",
    "thresh: The threshold value.\n",
    "maxval: The maximum value to use with the binary thresholding operations.\n",
    "type: The type of thresholding to apply (e.g., cv2.THRESH_BINARY, cv2.THRESH_BINARY_INV, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Read an image in grayscale\n",
    "image = cv2.imread(r\"C:\\Users\\lenovo 61IN\\Desktop\\opencv\\samples\\data\\pic2.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply binary thresholding\n",
    "ret, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Display the binary image\n",
    "cv2.imshow('Binary Image', binary_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  cv2.GaussianBlur():\n",
    "\n",
    "Purpose: This function is used to apply Gaussian smoothing to reduce noise and blur images.\n",
    "Parameters:\n",
    "src: The input image.\n",
    "ksize: The size of the Gaussian kernel. It should be a positive and odd integer (e.g., (5, 5)).\n",
    "sigmaX: The standard deviation of the Gaussian kernel in the X direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread(r\"C:\\Users\\lenovo 61IN\\Desktop\\opencv\\samples\\data\\apple.jpg\")\n",
    "\n",
    "# Apply Gaussian blur\n",
    "blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "# Display the blurred image\n",
    "cv2.imshow('Blurred Image', blurred_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.Canny():\n",
    "\n",
    "Purpose: This function is used to detect edges in an image using the Canny edge detection algorithm.\n",
    "Parameters:\n",
    "image: The input image.\n",
    "threshold1: The lower threshold for the hysteresis procedure.\n",
    "threshold2: The upper threshold for the hysteresis procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Read an image in grayscale\n",
    "image = cv2.imread(r\"C:\\Users\\lenovo 61IN\\Desktop\\opencv\\samples\\data\\home.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = cv2.Canny(image, 100, 200)\n",
    "\n",
    "# Display the edges\n",
    "cv2.imshow('Edges', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.dilate():\n",
    "\n",
    "Purpose: This function is used to dilate features in binary images, which increases the size of the foreground objects.\n",
    "Parameters:\n",
    "src: The input binary image.\n",
    "kernel: The structuring element used for dilation.\n",
    "iterations: The number of times dilation is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create a binary image\n",
    "binary_image = np.zeros((100, 100), dtype=np.uint8)\n",
    "binary_image[25:75, 25:75] = 255\n",
    "\n",
    "# Define the structuring element (kernel)\n",
    "kernel = np.ones((5, 5), dtype\n",
    "                 =np.uint8)\n",
    "\n",
    "# Apply dilation\n",
    "dilated_image = cv2.dilate(binary_image, kernel, iterations=1)\n",
    "\n",
    "# Display the dilated image\n",
    "cv2.imshow('Dilated Image', dilated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color conversion and Color Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 color schemes available\n",
    "\n",
    "RGB, RBG & HSV(Hue, Saturation, Lightness/Brightness) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    width = int(cap.get(3))\n",
    "    height = int(cap.get(4))\n",
    "\n",
    "    #cv2.COLOR_BGR2HSV is used to convert the frame/image from BGR to HSV format.\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    #hsv = cv2.flip(1)\n",
    "\n",
    "    # to extract color from the hsv image, we need to specify the lower bound and upper bound values.\n",
    "    # TIP: Google HSV color wheel to pick the color values of choice.\n",
    "    lower_blue = np.array([0,120,50])\n",
    "    upper_blue = np.array([100,150,255])\n",
    "\n",
    "    #NOTE: cv2.cvtColor() expects a frame which has a specific shape as an input so if we want to extarct a color from a single pixel, \n",
    "    #we can directly pass the color array like [255,0,0] instead we have to pass it as a numpy array which will be considered as a 1x1 image. \n",
    "    #hence the input should be a numpy array like [[[255,0,0]]]. so this [[[255,0,0]]] is a image with a single pixel.\n",
    "\n",
    "    #Mask is a portion of an image.\n",
    "\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue) # returns a new mask of an image which contain the frame of only the specified color.\n",
    "\n",
    "    # we are passing frame twice as source 1 & source 2 for the bitwise_and function, and use mask for filtering out only blue pixels. \n",
    "    # Basically we comparing the bit in our mask with the bits in our image.\n",
    "    result = cv2.bitwise_and(frame, frame, mask = mask) \n",
    "\n",
    "    cv2.imshow('frame', result)\n",
    "    cv2.imshow('mask', mask)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corner Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(r\"C:\\Users\\lenovo 61IN\\Desktop\\opencv\\samples\\data\\chessboard.png\")\n",
    "img = cv2.resize(img, (0,0), fx = 0.5, fy= 0.5)\n",
    "\n",
    "#  NOTE: while using techniques to detect corners, edges, or features, it is important to convert the image to grascale. as the algorithms work easier on grayscale images.\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# https://docs.opencv.org/4.x/d4/d8c/tutorial_py_shi_tomasi.html\n",
    "# cv2.goodFeaturesToTrack is used to detect corners.\n",
    "\n",
    "corners = cv2.goodFeaturesToTrack(gray, 100, 0.01, 10 ) # syntax: cv2.goodFeaturesToTrack(source image, number of corners, minimum quality, minimum euclidean distance)\n",
    "\n",
    "#convert corners from floating point values to integers.\n",
    "corners = np.intp(corners)\n",
    "\n",
    "#decomposition and drawing circles\n",
    "for corner in corners:\n",
    "    x, y = corner.ravel()  # ravel for flattening an array\n",
    "    cv2.circle(img, (x,y), 5, (255,0,0), -1) #drawing circle for each detected corner.\n",
    "\n",
    "## Drawing randomly coloured lines between corners\n",
    "for i in range(len(corners)):\n",
    "    for j in range(i+1, len(corners)):\n",
    "        corner1 = tuple(corners[i][0]) # converting to tuple as they are lists by default.\n",
    "        corner2 = tuple(corners[j][0])\n",
    "\n",
    "        color = tuple(map(lambda x: int(x), np.random.randint(0,255, size=3))) # here we are generating random RGB values and \n",
    "        cv2.line(img, corner1, corner2, color, 1)\n",
    "\n",
    "cv2.imshow(\"Frame\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEMPLATE MATCHING (OBJECT DETECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProjects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOpenCV-Tutorials\u001b[39m\u001b[38;5;130;01m\\a\u001b[39;00m\u001b[38;5;124mssets\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msoccer_practice.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m template \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProjects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOpenCV-Tutorials\u001b[39m\u001b[38;5;130;01m\\a\u001b[39;00m\u001b[38;5;124mssets\u001b[39m\u001b[38;5;130;01m\\b\u001b[39;00m\u001b[38;5;124mall.PNG\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mframe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     10\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "img = cv2.imread(\"E:\\Projects\\OpenCV-Tutorials\\assets\\soccer_practice.jpg\", -1)\n",
    "template = cv2.imread(\"E:\\Projects\\OpenCV-Tutorials\\assets\\ball.PNG\", -1)\n",
    "\n",
    "cv2.imshow(\"frame\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
